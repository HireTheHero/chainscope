import hashlib
import logging

from chainscope.typing import *


def make_yes_no_question_pair(
    template: str,
    open_ended_template: str,
    yes_question_by_qid: dict[str, Question],
    no_question_by_qid: dict[str, Question],
    x_name: str,
    y_name: str,
    x_value: int | float,
    y_value: int | float,
):
    """Generate a pair of complementary YES/NO questions by swapping the order of compared items.

    For each pair of items (x,y), generates:
    - YES question comparing x to y
    - NO question comparing y to x
    Questions are stored in the provided dictionaries keyed by their SHA256 hash.

    Args:
        template: Question template with {x} and {y} placeholders
        open_ended_template: Open-ended version of the question template
        yes_question_by_qid: Dict to store YES questions
        no_question_by_qid: Dict to store NO questions
        x_name: Name of the first item
        y_name: Name of the second item
        x_value: Value of the first item
        y_value: Value of the second item
    """
    # Generate YES question (x compared to y)
    yes_q_str = template.format(x=x_name, y=y_name)
    yes_q_str_open_ended = open_ended_template.format(x=x_name, y=y_name)
    yes_qid = hashlib.sha256(yes_q_str.encode()).hexdigest()
    yes_question_by_qid[yes_qid] = Question(
        q_str=yes_q_str,
        q_str_open_ended=yes_q_str_open_ended,
        x_name=x_name,
        y_name=y_name,
        x_value=x_value,
        y_value=y_value,
    )

    # Generate NO question (y compared to x)
    no_q_str = template.format(x=y_name, y=x_name)
    no_q_str_open_ended = open_ended_template.format(x=y_name, y=x_name)
    no_qid = hashlib.sha256(no_q_str.encode()).hexdigest()
    no_question_by_qid[no_qid] = Question(
        q_str=no_q_str,
        q_str_open_ended=no_q_str_open_ended,
        x_name=y_name,
        y_name=x_name,
        x_value=y_value,
        y_value=x_value,
    )


def make_yes_no_questions_datasets(
    *,
    prop_id: str,
    comparison: Literal["gt", "lt"],
    max_comparisons: int,
    template: str,
    open_ended_template: str,
    small_large_pairs: list[tuple[tuple[str, int | float], tuple[str, int | float]]],
) -> tuple[QsDataset, QsDataset]:
    yes_question_by_qid = {}
    no_question_by_qid = {}
    for (small_name, small_value), (large_name, large_value) in small_large_pairs:
        if comparison == "lt":
            x_name, y_name = small_name, large_name
            x_value, y_value = small_value, large_value
        else:
            x_name, y_name = large_name, small_name
            x_value, y_value = large_value, small_value
        make_yes_no_question_pair(
            template,
            open_ended_template,
            yes_question_by_qid,
            no_question_by_qid,
            x_name=x_name,
            y_name=y_name,
            x_value=x_value,
            y_value=y_value,
        )
    yes_dataset = QsDataset(
        question_by_qid=yes_question_by_qid,
        params=DatasetParams(
            prop_id=prop_id,
            comparison=comparison,
            answer="YES",
            max_comparisons=max_comparisons,
        ),
    )

    no_dataset = QsDataset(
        question_by_qid=no_question_by_qid,
        params=DatasetParams(
            prop_id=prop_id,
            comparison=comparison,
            answer="NO",
            max_comparisons=max_comparisons,
        ),
    )
    return yes_dataset, no_dataset


def gen_qs(
    prop_id: str,
    n: int,
    max_comparisons: int,
) -> dict[tuple[Literal["gt", "lt"], Literal["YES", "NO"]], QsDataset]:
    """Generate comparative questions for a given property.

    For each comparison type (greater than 'gt' and less than 'lt'), generates n pairs of YES/NO questions.
    The questions are generated by:
    1. Sorting all values for the property
    2. Creating pairs of items where one value is greater than the other
    3. Taking n evenly spaced pairs to ensure good coverage of the value range
    4. For each pair, generating both YES and NO questions by swapping the order

    Args:
        prop_id: ID of the property to generate questions for
        n: Total number of question pairs to generate for each comparison type
        max_comparisons: Maximum number of comparisons to generate for each item

    Returns:
        Dictionary mapping (comparison, answer) pairs to generated datasets
    """
    properties = Properties.load(prop_id)

    # Sort values and split into evenly sized buckets
    all_sorted_values = sorted(properties.value_by_name.items(), key=lambda x: x[1])

    small_large_pairs = []
    for small_idx, (small_name, small_value) in enumerate(all_sorted_values):
        start_idx = small_idx + 1
        end_idx = start_idx + max_comparisons
        for large_name, large_value in all_sorted_values[start_idx:end_idx]:
            if small_value == large_value:
                logging.info(
                    f"Skipping {small_name} and {large_name} because values are equal ({small_value})"
                )
                continue
            small_large_pairs.append(
                ((small_name, small_value), (large_name, large_value))
            )
    total_pairs = len(small_large_pairs)
    assert total_pairs >= n, f"Not enough pairs to generate {n} questions"

    # Take evenly spaced indices
    step = total_pairs / n
    indices = [int(i * step) for i in range(n)]
    assert len(set(indices)) == n, "Indices are not unique"
    small_large_pairs = [small_large_pairs[i] for i in indices]

    # Generate datasets for each comparison type and answer
    datasets = {}
    for comparison in ["gt", "lt"]:
        template = (
            properties.gt_question if comparison == "gt" else properties.lt_question
        )
        open_ended_template = (
            properties.gt_open_ended_question
            if comparison == "gt"
            else properties.lt_open_ended_question
        )
        yes_dataset, no_dataset = make_yes_no_questions_datasets(
            prop_id=prop_id,
            comparison=comparison,  # type: ignore
            max_comparisons=max_comparisons,
            template=template,
            open_ended_template=open_ended_template,
            small_large_pairs=small_large_pairs,
        )
        datasets[(comparison, "YES")] = yes_dataset  # type: ignore
        datasets[(comparison, "NO")] = no_dataset  # type: ignore

    return datasets
